---
title: "人工智能术语解释表"
author: "乔炳栋"
categories: [planet]
tags: []
---
# 人工智能术语解释表

| 名词         | 英文                              | 解释                                                                                                                                                                                                 |
|--------------|-----------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| AI           | Artificial Intelligence           | 人工智能。就像机器人的大脑，能让电脑或设备像人一样思考、学习和做事情，比如语音助手帮你查天气、自动驾驶汽车自己开车，都是AI在发挥作用。                                                                 |
| GPT          | Generative Pre-trained Transformer | GPT是一种基于深度学习的自然语言处理模型，通过大规模文本数据的预训练，能够生成连贯、相关的文本内容，广泛应用于语言生成、翻译、问答等多种场景。由OpenAI公司开发，2025年2月27日最新发布版本是GPT-4.5。        |
| ChatGPT      | Chat Generative Pre-trained Transformer | ChatGPT 是一个基于GPT技术的人工智能聊天机器人，能够通过对话理解用户的问题，并用自然语言生成回答，帮助用户完成各种语言相关的需求。由OpenAI公司在2022年11月30日推出，基于GPT-3.5架构。                     |
| 生成式AI     | Generative AI                     | 生成式AI。一种能够根据输入的提示或指令生成新内容的人工智能技术。它可以创作文本、图像、音频、视频等内容，就像一个“创作机器”，通过学习海量数据来模仿人类的创作方式。                                       |
| AIGC         | Artificial Intelligence Generated Content | 人工智能生成内容。让AI像人类一样创作出各种内容，比如写文章、画画、编曲、制作视频等。                                                                                                                 |
| 提示词       | Prompt                            | 用户提供给人工智能系统并期望某些结果的输入，比如输入给ChatGPT或者Midjourney的内容。                                                                                                                  |
| AGI          | Artificial General Intelligence   | 通用人工智能。是一种能够像人类一样处理各种复杂任务的智能系统。弱人工智能通常只能在特定领域（如图像识别、语言翻译或棋类游戏）表现出智能，而 AGI 的目标是具备跨领域的通用智能，能够像人类一样自主学习、推理和适应各种复杂任务，无需针对每个任务进行专门设计或训练。 |
| 智能体       | Agent                             | Agent就像是一个“智能助手”，它能够感知环境、做出决策并采取行动。Agent可以是简单的（比如聊天机器人），也可以是复杂的（比如自动驾驶汽车）。它们广泛应用于我们的生活和工作中，帮助我们完成各种任务。         |
| Manus        | Avatar Manus                      | Avatar Manus 是一款由中国团队 Monica.im 研发的通用型 AI Agent（人工智能代理），于2025年3月6日正式发布。Manus能够独立思考、规划并执行复杂任务，直接交付完整成果。Manus可以在云端自动调用浏览器、虚拟机、Python完成任务。 |
| NLP          | Natural Language Processing       | 自然语言处理。让电脑学会理解人类的语言。比如，你和语音助手聊天，它能听懂你说的话，还能用文字或语音回答你，这就是NLP的功劳。                                                                          |
| 机器学习     | Machine Learning                  | 机器学习就是让电脑通过数据自己“学习”规律的技术。比如，给电脑看很多猫和狗的图片，它会自动找出猫和狗的区别，以后就能自己判断新图片是猫还是狗。                                                           |
| 深度学习     | Deep Learning                     | 深度学习是机器学习的一种高级方法，它通过模仿人脑的神经网络结构，让电脑能够自动学习更复杂的模式和规律。比如，它可以用来识别语音、图像，甚至预测天气，就像电脑有了更聪明的“大脑”。                         |
| 神经网络     | Neural Network                    | 神经网络是一种模仿人脑神经细胞工作方式的计算模型。它由很多节点（像神经元）组成，这些节点相互连接，通过不断调整连接的强度来学习数据中的规律，从而完成任务。                                               |
| Transformer架构 | Transformer Architecture          | Transformer架构是一种基于编码器-解码器（Encoder-Decoder）的深度学习模型，主要用于处理序列数据，如自然语言处理中的翻译、生成等任务。                                                                 |
| 数据集       | Dataset                           | 数据集就是一堆用来训练AI模型的数据，就像是一堆学习材料。比如一堆图片、文字或者语音记录。                                                                                                            |
| 大数据       | Big Data                          | 大数据就是海量的数据集合，数据量大到普通电脑和软件很难处理。这些数据来自各种地方，比如互联网、传感器、社交媒体等。通过分析大数据，可以发现规律、趋势，帮助做决策，比如预测天气、推荐商品等。             |
| 大模型       | Large Model                       | 大模型是指参数规模庞大（通常达到数亿甚至数千亿）的深度学习模型。                                                                                                                                  |
| 参数         | Parameters                        | 举个简单的例子，假如有一个模型，它的任务是根据房子的面积来预测房价。模型可能会有一个规则，比如“房价 = 面积 × 某个数值 + 另一个数值”。这里的“某个数值”和“另一个数值”就是参数。模型通过学习数据（比如很多房子的面积和对应的价格），调整这些参数，让预测的结果更接近真实情况。大模型需要大量参数，这样它才能做出更准确的预测。 |
| LLM          | Large Language Model              | 大型语言模型。大型语言模型（LLM，Large Language Model）是一种基于深度学习技术构建的人工智能模型，旨在理解和生成人类语言。                                                                              |
| VLM          | Vision Language Model             | 视觉语言模型。视觉语言模型是一种多模态模型，结合了视觉（图像或视频）和语言（文本）的处理能力。它可以同时处理图像和文本输入，执行视觉问答、图像字幕生成等任务。                                           |
| LLaMA        | Large Language Model Meta AI      | 大语言模型元AI。由 Meta 发布的开源大语言模型。一个有着上百亿数量级参数的大语言模型，用于大规模部署和管理机器学习元模型。                                                                              |
| 推理大模型   | Reasoning Large Model             | 推理大模型是指能够在传统的大语言模型基础上，强化推理、逻辑分析和决策能力的模型。它们通常具备额外的技术，比如强化学习、神经符号推理、元学习等，来增强其推理和问题解决能力。例如：DeepSeek-R1，GPT-o3在逻辑推理、数学推理和实时问题解决方面表现突出。 |
| 非推理大模型 | Non-Reasoning Large Model         | 适用于大多数任务，非推理大模型一般侧重于语言生成、上下文理解和自然语言处理，而不强调深度推理能力。此类模型通常通过对大量文本数据的训练，掌握语言规律并能够生成合适的内容，但缺乏像推理模型那样复杂的推理和决策能力。例如：GPT-3、GPT-4（OpenAI），BERT（Google），主要用于语言生成、语言理解、文本分类、翻译等任务。 |
| AI幻觉       | AI hallucination                  | AI幻觉是指生成式人工智能在输出内容时，生成了与输入文本或真实世界知识相矛盾的事实错误或逻辑错误。                                                                                                      |
| 多模态AI     | Multimodal AI                     | 多模态 AI 系统能够以多种媒介处理输入并产生输出。多模态系统可以处理图像、视频、文本或声音的任何组合，而不仅仅是文本。                                                                                  |
| MOE          | Mixture of Experts                | 混合专家模型。它就像一个团队合作的系统，里面有多个“专家”，每个专家擅长处理不同类型的任务或数据。当遇到一个问题时，系统会根据问题的特点，让不同的专家来处理，或者综合多个专家的意见，最终给出一个更准确的结果。就好像一个公司里有不同部门的专家，大家一起合作解决问题一样。 |
| 数据集       | Dataset                           | 数据集就是给AI用来学习的“教材”，就像学生上课用的课本。AI通过这些数据学习规律，变得聪明。                                                                                                            |
| Token        | Token                             | Token就像是语言里的“小零件”，把句子拆成一个个小块。比如，“我爱吃苹果”可以拆成“我”“爱”“吃”“苹果”四个Token。AI处理语言时，会先把它拆成这样的小块，方便理解和生成。【Token离线计算】                        |
| GPU          | Graphics Processing Unit          | GPU是图形处理器，就像电脑里的“超级助手”，专门用来处理复杂的图像和计算任务。它有很多小核心，能同时做很多事，比如玩游戏时渲染画面，或者训练AI模型时快速计算，让电脑运行得更快。它比普通的CPU更适合做复杂的数学计算，尤其是并行计算。 |
| 训练         | Training                          | 训练就是让AI学习的过程。就像教小孩认字，给AI很多数据，让它从中找规律、学知识，慢慢变得聪明，能完成任务。                                                                                              |
| 预训练模型   | Pre-trained Model                 | 预训练模型就是在超大的数据集上先训练好的模型，它学会了通用的知识和规律，比如语言的语法、词汇等。然后，我们可以在小数据集上对它进行微调，让它适应具体任务，比如翻译、问答等。如果AI模型从零开始学习，就像一个人从头开始学知识，那会花很多时间。预训练模型已经学了很多通用的知识，所以它可以直接拿来用，或者稍微调整一下就能完成任务。 |
| 模型基座     | Base Model                        | 预训练得到的结果。想象一下，你要做一个智能语音助手，比如像Siri或者小爱同学这样的产品。如果你从零开始，需要收集海量的语音数据，然后一点点地训练模型，让它能够理解语言、回答问题。这个过程非常复杂，而且需要大量的时间和资源。但有了“模型基座”之后，就好比你已经有了一个已经打好基础的房子框架。这个框架已经具备了一些基本能力，比如能听懂一些简单的话、能做基本的对话。然后你只需要在这个基础上，根据自己的需求，比如让它更懂方言、或者让它能回答一些特定领域的问题，做一些“装修”和“调整”就可以了。 |
| 微调         | Fine-tuning                       | 微调就是对预训练好的模型进行“再教育”，让它适应特定的任务。比如，预训练模型学会了通用语言知识，微调就是让它专门学习写新闻或者做翻译，让它更擅长这个任务。                                                                                                            |
| 模型蒸馏     | Model Distillation                | 大模型的文件太大了，对计算机的算力要求很高。模型蒸馏是一种将大模型的知识“浓缩”后传递给小模型的技术。简单来说，就像让一个“学霸老师”教出一个“学神学生”，学生模型通过模仿教师模型的输出结果，学习到类似的知识和能力。                                                         |
| 推理         | Inference                         | 推理就是AI模型在训练好之后，用学到的知识去解决实际问题的过程。比如，AI学会了识别图片里的猫和狗，推理就是它看到一张新图片后，判断这是猫还是狗。                                                                                                                      |
| 超参数       | Hyperparameters                   | 在AI模型中，超参数就像是“控制旋钮”，用来调整模型的行为和输出。不同的超参数设置会影响模型的表现，比如生成的内容风格、准确性和多样性等。                                                                 |
| RAG          | Retrieval-Augmented Generation    | 检索增强生成。AI训练的数据会停留在一个时间节点，因此会出现某些信息过时的情况。RAG是一种结合检索技术和生成模型的人工智能方法。它通过从外部知识库中检索相关信息（包括搜索引擎、链接、文件），并将其作为上下文输入给大语言模型（LLM），从而增强模型在知识密集型任务中的表现。 |
| MCP          | Model Context Protocol            | 模型上下文协议。是由 Anthropic 公司（Claude母公司）推出的一种开放标准协议。简单来说，它就像是 AI 的“万能连接器”，可以让 AI 大模型（比如 Claude 或其他语言模型）轻松地和外部世界“握手”，连接各种数据源和工具。举个例子，假设你有一个超级聪明的机器人助手，但它只能回答问题，却没办法自己去查资料或者操作其他设备。MCP 就像是给这个机器人装了一个“万能插头”，让它可以连接到冰箱查看库存、连接到手机查看日程，或者上网查天气。 |
